{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to 'dataset_binario.csv'. Total rows: 1666, JSON files processed: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def process_json_directory(directory_path, output_csv='dataset.csv'):\n",
    "    \"\"\"\n",
    "    Processes all JSON files in the given directory to create a binary classification dataset.\n",
    "    - Extracts abstracts as complex (label 1)\n",
    "    - Extracts adaptations as simple (label 0)\n",
    "    - Saves the result to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing JSON files.\n",
    "        output_csv (str): Path to save the output CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the dataset was saved successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    # Validate directory\n",
    "    if not os.path.exists(directory_path) or not os.path.isdir(directory_path):\n",
    "        print(f\"Error: '{directory_path}' is not a valid directory.\")\n",
    "        return False\n",
    "\n",
    "    texts = []\n",
    "    labels = []\n",
    "    json_files_processed = 0\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Traverse the nested structure\n",
    "                for q_id in data:\n",
    "                    question_data = data[q_id]\n",
    "                    # Find PMID keys\n",
    "                    pmid_keys = [k for k in question_data if k.startswith('PMID_') or k.isdigit()]  # Adjusted for your sample\n",
    "                    for pmid in pmid_keys:\n",
    "                        pmid_data = question_data[pmid]\n",
    "                        \n",
    "                        # Extract abstract\n",
    "                        if 'abstract' in pmid_data:\n",
    "                            abstract_sentences = pmid_data['abstract']\n",
    "                            # Sort sentence keys by number\n",
    "                            sorted_abstract_keys = sorted(\n",
    "                                abstract_sentences.keys(),\n",
    "                                key=lambda x: int(x)\n",
    "                            )\n",
    "                            abstract_text = ' '.join(abstract_sentences[k] for k in sorted_abstract_keys)\n",
    "                            if abstract_text.strip():  # Ensure non-empty text\n",
    "                                texts.append(abstract_text)\n",
    "                                labels.append(1)\n",
    "                        \n",
    "                        # Extract adaptations\n",
    "                        if 'adaptations' in pmid_data:\n",
    "                            adaptations = pmid_data['adaptations']\n",
    "                            for adapt_key in adaptations:\n",
    "                                adapt_sentences = adaptations[adapt_key]\n",
    "                                # Sort sentence keys by number\n",
    "                                sorted_adapt_keys = sorted(\n",
    "                                    adapt_sentences.keys(),\n",
    "                                    key=lambda x: int(x)\n",
    "                                )\n",
    "                                adapt_text = ' '.join(adapt_sentences[k] for k in sorted_adapt_keys)\n",
    "                                if adapt_text.strip():  # Ensure non-empty text\n",
    "                                    texts.append(adapt_text)\n",
    "                                    labels.append(0)\n",
    "                \n",
    "                json_files_processed += 1\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Warning: Skipping '{filename}' due to invalid JSON format.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing '{filename}': {str(e)}\")\n",
    "\n",
    "    # Check if any data was collected\n",
    "    if not texts:\n",
    "        print(\"No valid data extracted from JSON files.\")\n",
    "        return False\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({'text': texts, 'label': labels})\n",
    "\n",
    "    # Remove duplicates (optional)\n",
    "    df = df.drop_duplicates(subset=['text'], keep='first')\n",
    "\n",
    "    # Save to CSV\n",
    "    try:\n",
    "        df.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "        print(f\"Dataset saved to '{output_csv}'. Total rows: {len(df)}, JSON files processed: {json_files_processed}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to save CSV to '{output_csv}': {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "process_json_directory('.', 'dataset_binario.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da54259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5089c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
